{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding path to import custom functions\n",
    "import sys\n",
    "sys.path.append(\"/home/artur/code/masters-project/main_project/notebooks/model_creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from time import perf_counter, gmtime, strftime\n",
    "\n",
    "from functions import remove_high_corr, scale_variables, best_params_grid, calculate_confusion_matrix, plot_roc_auc_curve, bart_auc_scorer, make_label, get_error_and_auc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold, train_test_split, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, make_scorer\n",
    "\n",
    "from ISLP.bart import BART\n",
    "\n",
    "import session_info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/pre_processed_zinc_mordred_2d.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[\"fda_approved\"]\n",
    "Y = Y.astype(float)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 14:-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate train an test datasets\n",
    "\n",
    "np.random.seed(750059)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, stratify=Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTOR_TYPE = \"mordred\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling datsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets are being scaled to be used, when necessary, scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "\n",
    "x_train_scaled = scale_variables(x_train)\n",
    "\n",
    "# adding constant\n",
    "x_train_scaled = sm.add_constant(x_train_scaled)\n",
    "\n",
    "x_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "x_test_scaled = scale_variables(x_test)\n",
    "\n",
    "# adding constant\n",
    "x_test_scaled = sm.add_constant(x_test_scaled)\n",
    "\n",
    "x_test_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_title = \"Logistic Regression\"\n",
    "model_name_path = \"logistic_regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I will use the best_params_grid function, which looks for the best hyperparameters, using CV. There are no hyperparameters in Logistic Regression, so this function will only perform CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_lr = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_lr, gs_result_lr_full = best_params_grid(x_train, y_train, model_params_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Model to Train Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit the model, I will use the Logit function, from the statsmodel library, because it gives more information about feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting y_train index and type\n",
    "\n",
    "y_train.index = range(0, x_train_scaled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculatin model\n",
    "log_reg = sm.Logit(y_train, x_train_scaled).fit(method='bfgs')\n",
    "log_reg_results = log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Error and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate_lr_train, auc_lr_train = get_error_and_auc(\n",
    "    model=log_reg, \n",
    "    x=x_train_scaled,\n",
    "    y_true=y_train,\n",
    "    transform_prob_into_label=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the log_reg algorithm predicts as probabilities\n",
    "y_predict_lr_prob = log_reg.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I use the make_label function to transform the probabilities into labels, using 0.5 as a cutoff\n",
    "\n",
    "make_label_v = np.vectorize(make_label)\n",
    "y_predict_labels_lr = make_label_v(y_predict_lr_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate_lr, disp = calculate_confusion_matrix(\n",
    "    y_test=y_test, \n",
    "    y_pred=y_predict_labels_lr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.plot()\n",
    "plt.title(f\"Confusion Matrix: {model_name_title}\\nOral vc Non Oral, {DESCRIPTOR_TYPE}\")\n",
    "disp.figure_.savefig(f\"imgs/cm_{DESCRIPTOR_TYPE}_{model_name_path}\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_lr = plot_roc_auc_curve(\n",
    "    y_test=y_test,\n",
    "    y_pred=y_predict_lr_prob,\n",
    "    model_name=model_name_title,\n",
    "    title=f\"AUC - ROC: {model_name_title}\\nOral vc Non Oral, {DESCRIPTOR_TYPE}\",\n",
    "    save_path=f\"imgs/roc_auc_{DESCRIPTOR_TYPE}_{model_name_path}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting results summary to pandas dataframe\n",
    "results_log_reg_html = log_reg_results.tables[1].as_html()\n",
    "results_log_reg_df = pd.read_html(results_log_reg_html, header=0, index_col=0)[0]\n",
    "print(results_log_reg_df.shape)\n",
    "results_log_reg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_lr = results_log_reg_df[results_log_reg_df[\"P>|z|\"] < 0.05]\n",
    "print(important_features_lr.shape)\n",
    "important_features_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataset to store final results from each model\n",
    "final_results = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"model_name\", \n",
    "        \"cv_test_auc\", \n",
    "        \"training_mis_rate\", \n",
    "        \"test_mis_rate\", \n",
    "        \"training_auc\",\n",
    "        \"test_auc\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.loc[len(final_results.index)] = [\n",
    "    model_name_title,\n",
    "    gs_result_lr[\"best_score\"][0],\n",
    "    mis_rate_lr_train,\n",
    "    mis_rate_lr,\n",
    "    auc_lr_train,\n",
    "    auc_lr\n",
    "]\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_lr.to_csv(f\"final_results/important_features_{model_name_path}_{DESCRIPTOR_TYPE}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_title = \"Decision Tree\"\n",
    "model_name_path = \"decision_tree\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "            'max_depth': [1, 5, 10, 20, 50, 100, 150],\n",
    "            'ccp_alpha': [0, 0.0001, 0.001, 0.1, 0.5, 1]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_dt, gs_result_dt_full = best_params_grid(x_train, y_train, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_params = gs_result_dt.iloc[0,2]\n",
    "decision_tree_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(**decision_tree_params).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Error and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate_dt_train, auc_dt_train = get_error_and_auc(\n",
    "    model=decision_tree, \n",
    "    x=x_train,\n",
    "    y_true=y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_dt_label = decision_tree.predict(x_test)\n",
    "y_predict_dt_prob = decision_tree.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate_dt, disp = calculate_confusion_matrix(\n",
    "    y_test=y_test, \n",
    "    y_pred=y_predict_dt_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.plot()\n",
    "plt.title(f\"Confusion Matrix: {model_name_title}\\nOral vc Non Oral, {DESCRIPTOR_TYPE}\")\n",
    "disp.figure_.savefig(f\"imgs/cm_{DESCRIPTOR_TYPE}_{model_name_path}\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_dt = plot_roc_auc_curve(\n",
    "    y_test=y_test,\n",
    "    y_pred=y_predict_dt_prob,\n",
    "    model_name=model_name_title,\n",
    "    title=f\"AUC - ROC: {model_name_title}\\nOral vc Non Oral, {DESCRIPTOR_TYPE}\",\n",
    "    save_path=f\"imgs/roc_auc_{DESCRIPTOR_TYPE}_{model_name_path}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.dpi = 1000\n",
    "\n",
    "tree.plot_tree(decision_tree, ax=ax, feature_names=list(x_train.columns))\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f\"imgs/decision_tree_{DESCRIPTOR_TYPE}\", dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the feature importances\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "feat_importances = pd.DataFrame(decision_tree.feature_importances_, index=x_train.columns, columns=[\"Importance\"])\n",
    "feat_importances.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "feat_importances.iloc[:30,:].plot(kind='bar', figsize=(8,6), ax=ax)\n",
    "ax.set_title(f\"Feature Importance: {model_name_title}\\nOral vc None Oral, {DESCRIPTOR_TYPE}\")\n",
    "\n",
    "fig.savefig(f\"imgs/feature_importance_{DESCRIPTOR_TYPE}_{model_name_path}\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_dt = feat_importances[feat_importances.Importance > 0].sort_values(by=\"Importance\")\n",
    "important_features_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.loc[len(final_results.index)] = [\n",
    "    model_name_title,\n",
    "    gs_result_dt[\"best_score\"][0],\n",
    "    mis_rate_dt_train,\n",
    "    mis_rate_dt,\n",
    "    auc_dt_train,\n",
    "    auc_dt\n",
    "]\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_dt.to_csv(f\"final_results/important_features_{model_name_path}_{DESCRIPTOR_TYPE}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest and Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging is just Random Forest, in which max_features is equal to the total number of features. Therefore, bagging will be done in the RF algorithm, and compared to RF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_title = \"Random Forest\"\n",
    "model_name_path = \"random_forest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 500, 1000], # number of trees\n",
    "            'max_depth': [10, 50, 100],\n",
    "            'max_features': [\"sqrt\", \"log2\"], # m, number of features considered in split. When it is equal to all predictor of dataset, it is bagging\n",
    "            'ccp_alpha': [0.1, 0.5]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_rf, gs_result_rf_full = best_params_grid(x_train, y_train, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_params = gs_result_rf.iloc[0,2]\n",
    "random_forest_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(**random_forest_params).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Error and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate_rf_train, auc_rf_train = get_error_and_auc(\n",
    "    model=random_forest, \n",
    "    x=x_train,\n",
    "    y_true=y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_rf_label = random_forest.predict(x_test)\n",
    "y_predict_rf_prob = random_forest.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate_rf, disp = calculate_confusion_matrix(\n",
    "    y_test=y_test, \n",
    "    y_pred=y_predict_rf_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.plot()\n",
    "plt.title(f\"Confusion Matrix: {model_name_title}\\nOral vc Non Oral, {DESCRIPTOR_TYPE}\")\n",
    "disp.figure_.savefig(f\"imgs/cm_{DESCRIPTOR_TYPE}_{model_name_path}\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_rf = plot_roc_auc_curve(\n",
    "    y_test=y_test,\n",
    "    y_pred=y_predict_rf_prob,\n",
    "    model_name=model_name_title,\n",
    "    title=f\"AUC - ROC: {model_name_title}\\nOral vc Non Oral, {DESCRIPTOR_TYPE}\",\n",
    "    save_path=f\"imgs/roc_auc_{DESCRIPTOR_TYPE}_{model_name_path}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the feature importances\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "feat_importances = pd.DataFrame(random_forest.feature_importances_, index=x_train.columns, columns=[\"Importance\"])\n",
    "feat_importances.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "feat_importances.iloc[:30,:].plot(kind='bar', figsize=(8,6), ax=ax)\n",
    "ax.set_title(f\"Feature Importance: {model_name_title}\\nOral vc None Oral, {DESCRIPTOR_TYPE}\")\n",
    "\n",
    "fig.savefig(f\"imgs/feature_importance_{DESCRIPTOR_TYPE}_{model_name_path}\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_rf = feat_importances[feat_importances.Importance > 0].sort_values(by=\"Importance\")\n",
    "important_features_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.loc[len(final_results.index)] = [\n",
    "    model_name_title,\n",
    "    gs_result_rf[\"best_score\"][0],\n",
    "    mis_rate_rf_train,\n",
    "    mis_rate_rf,\n",
    "    auc_rf_train,\n",
    "    auc_rf\n",
    "]\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_rf.to_csv(f\"final_results/important_features_{model_name_path}_{DESCRIPTOR_TYPE}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_title = \"Gradiant Boosting\"\n",
    "model_name_path = \"boosting\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'Boosting': {\n",
    "            'model': GradientBoostingClassifier(),\n",
    "            'params': {\n",
    "                'n_estimators' : [100, 500], # number of trees\n",
    "                'learning_rate': [0.01, 0.1], # alfa\n",
    "                'max_depth': [20],\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_boo, gs_result_boo_full = best_params_grid(x_train_scaled, y_train, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_boo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_params = gs_result_boo.iloc[0,2]\n",
    "boosting_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting = GradientBoostingClassifier(**boosting_params).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Error and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate_boo_train, auc_boo_train = get_error_and_auc(\n",
    "    model=boosting, \n",
    "    x=x_train,\n",
    "    y_true=y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_boo_label = boosting.predict(x_test)\n",
    "y_predict_boo_prob = boosting.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate_boo, disp = calculate_confusion_matrix(\n",
    "    y_test=y_test, \n",
    "    y_pred=y_predict_boo_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.plot()\n",
    "plt.title(f\"Confusion Matrix: {model_name_title}\\nOral vc Non Oral, {DESCRIPTOR_TYPE}\")\n",
    "disp.figure_.savefig(f\"imgs/cm_{DESCRIPTOR_TYPE}_{model_name_path}\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_boo = plot_roc_auc_curve(\n",
    "    y_test=y_test,\n",
    "    y_pred=y_predict_boo_prob,\n",
    "    model_name=model_name_title,\n",
    "    title=f\"AUC - ROC: {model_name_title}\\nOral vc Non Oral, {DESCRIPTOR_TYPE}\",\n",
    "    save_path=f\"imgs/roc_auc_{DESCRIPTOR_TYPE}_{model_name_path}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the feature importances\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "feat_importances = pd.DataFrame(boosting.feature_importances_, index=x_train.columns, columns=[\"Importance\"])\n",
    "feat_importances.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "feat_importances.iloc[:30,:].plot(kind='bar', figsize=(8,6), ax=ax)\n",
    "ax.set_title(f\"Feature Importance: {model_name_title}\\nOral vc None Oral, {DESCRIPTOR_TYPE}\")\n",
    "\n",
    "fig.savefig(f\"imgs/feature_importance_{DESCRIPTOR_TYPE}_{model_name_path}\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_boo = feat_importances[feat_importances.Importance > 0].sort_values(by=\"Importance\")\n",
    "important_features_boo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.loc[len(final_results.index)] = [\n",
    "    model_name_title,\n",
    "    gs_result_boo[\"best_score\"][0],\n",
    "    mis_rate_boo_train,\n",
    "    mis_rate_boo,\n",
    "    auc_boo_train,\n",
    "    auc_boo\n",
    "]\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_boo.to_csv(f\"final_results/important_features_{model_name_path}_{DESCRIPTOR_TYPE}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_title = \"BART\"\n",
    "model_name_path = \"bart\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming x train and test as arrays for BART procedure\n",
    "\n",
    "x_train_bart = np.asarray(x_train)\n",
    "x_test_bart = np.asarray(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'BART': {\n",
    "        'model': BART(),\n",
    "        'params': {\n",
    "            'num_trees': [100, 500, 1000],\n",
    "            'max_stages': [100, 500, 800, 1000], # B, number of iterations\n",
    "            'burnin': [5, 10, 20] #L\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For BART, the auc present in the best_params_grid need to recieve the y_predicted in labels, but this BART algorithm does it in probabilities. Because of this, I need to use a custom scorer, that first transforms the prediction to labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = make_scorer(bart_auc_scorer, greater_is_better=True)\n",
    "\n",
    "gs_result_bart, gs_result_bart_full = best_params_grid(x_train_bart, y_train, model_params, scoring=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_bart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_params = gs_result_bart.iloc[0,2]\n",
    "bart_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = BART(**bart_params)\n",
    "bart.fit(x_train_bart, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Error and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate_bart_train, auc_bart_train = get_error_and_auc(\n",
    "    model=bart, \n",
    "    x=x_train_bart,\n",
    "    y_true=y_train,\n",
    "    transform_prob_into_label=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bart algorithm predicts as probabilities\n",
    "y_predict_bart_prob = bart.predict(x_test_bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I use the make_label function to transform the probabilities into labels, using 0.5 as a cutoff\n",
    "\n",
    "y_predict_bart_label = make_label_v(y_predict_bart_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate_bart, disp = calculate_confusion_matrix(\n",
    "    y_test=y_test, \n",
    "    y_pred=y_predict_bart_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.plot()\n",
    "plt.title(f\"Confusion Matrix: {model_name_title}\\nOral vc Non Oral, {DESCRIPTOR_TYPE}\")\n",
    "disp.figure_.savefig(f\"imgs/cm_{DESCRIPTOR_TYPE}_{model_name_path}\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_bart = plot_roc_auc_curve(\n",
    "    y_test=y_test,\n",
    "    y_pred=y_predict_bart_prob,\n",
    "    model_name=model_name_title,\n",
    "    title=f\"AUC - ROC: {model_name_title}\\nOral vc Non Oral, {DESCRIPTOR_TYPE}\",\n",
    "    save_path=f\"imgs/roc_auc_{DESCRIPTOR_TYPE}_{model_name_path}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how many times each variable appeared in the collection\n",
    "of trees. This gives a summary similar to the variable importance plot for\n",
    "boosting and random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the feature importances\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "feat_importances = pd.DataFrame(columns=[\"Importance\"])\n",
    "feat_importances[\"Importance\"] = pd.Series(bart.variable_inclusion_.mean(0),index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "feat_importances.iloc[:30,:].plot(kind='bar', figsize=(8,6), ax=ax)\n",
    "ax.set_title(f\"Feature Importance: {model_name_title}\\nOral vc None Oral, {DESCRIPTOR_TYPE}\")\n",
    "\n",
    "fig.savefig(f\"imgs/feature_importance_{DESCRIPTOR_TYPE}_{model_name_path}\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_bart = feat_importances[feat_importances.Importance > 0].sort_values(by=\"Importance\")\n",
    "important_features_bart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.loc[len(final_results.index)] = [\n",
    "    model_name_title,\n",
    "    gs_result_bart[\"best_score\"][0],\n",
    "    mis_rate_bart_train,\n",
    "    mis_rate_bart,\n",
    "    auc_bart_train,\n",
    "    auc_bart\n",
    "]\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_bart.to_csv(f\"final_results/important_features_{model_name_path}_{DESCRIPTOR_TYPE}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_title = \"SVM\"\n",
    "model_name_path = \"svm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1 / (x_train.shape[1] * x_train.var().mean())\n",
    "\n",
    "model_params = {\n",
    "    'SVM': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'C': [0.1, 0.3, 0.5, 0.8, 1.0, 2, 5, 10],\n",
    "            'kernel': ['rbf', 'sigmoid'],\n",
    "            'gamma': ['auto', scale, 0.0001, 0.001, 0.01, 0.1, 0.5, 1, 10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_svm, gs_result_svm_full = best_params_grid(x_train, y_train, model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = gs_result_svm.iloc[0,2]\n",
    "svm_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(**svm_params, probability=True).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Error and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate_svm_train, auc_svm_train = get_error_and_auc(\n",
    "    model=svm, \n",
    "    x=x_train,\n",
    "    y_true=y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_svm_label = svm.predict(x_test)\n",
    "y_predict_svm_prob = svm.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_rate_svm, disp = calculate_confusion_matrix(\n",
    "    y_test=y_test, \n",
    "    y_pred=y_predict_svm_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp.plot()\n",
    "plt.title(f\"Confusion Matrix: {model_name_title}\\nOral vc Non Oral, {DESCRIPTOR_TYPE}\")\n",
    "disp.figure_.savefig(f\"imgs/cm_{DESCRIPTOR_TYPE}_{model_name_path}\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_svm = plot_roc_auc_curve(\n",
    "    y_test=y_test,\n",
    "    y_pred=y_predict_svm_prob,\n",
    "    model_name=model_name_title,\n",
    "    title=f\"AUC - ROC: {model_name_title}\\nOral vc Non Oral, {DESCRIPTOR_TYPE}\",\n",
    "    save_path=f\"imgs/roc_auc_{DESCRIPTOR_TYPE}_{model_name_path}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.loc[len(final_results.index)] = [\n",
    "    model_name_title,\n",
    "    gs_result_svm[\"best_score\"][0],\n",
    "    mis_rate_svm_train,\n",
    "    mis_rate_svm,\n",
    "    auc_svm_train,\n",
    "    auc_svm\n",
    "]\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Final Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving final_results dataset\n",
    "final_results.to_csv(f\"final_results/models_results_{DESCRIPTOR_TYPE}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teachopencadd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
